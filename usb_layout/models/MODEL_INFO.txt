# MiniBeast LLM Model Information

Model: TinyLlama-1.1B-Chat-v1.0
Quantization: Q2_K (2-bit quantization)
Size: 461 MB (483,116,416 bytes)
SHA-256: 030a469a63576d59f601ef5608846b7718eaa884dd820e9aa7493efec1788afa

Source: https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF
License: Apache 2.0
Downloaded: 2025-11-09

Purpose:
This model is used for generating human-readable system analysis reports
from collected system facts. It operates entirely offline with no network
requirements.

Technical Specifications:
- Context Window: 2048 tokens
- Architecture: Llama 2
- Parameters: 1.1 billion
- Inference Speed: ~11 tokens/second (typical CPU)
- Memory Usage: ~30MB RSS + 461MB mmap (virtual)

Verification:
To verify model integrity, run:
  sha256sum tinyllama-1.1b-chat-v1.0.Q2_K.gguf
  
Expected output:
  030a469a63576d59f601ef5608846b7718eaa884dd820e9aa7493efec1788afa
